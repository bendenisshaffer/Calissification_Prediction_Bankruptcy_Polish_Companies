italy_data$POS = as.numeric(italy_data$POS)
italy_data$Overall_P = as.numeric(italy_data$Overall_P)
italy_data$Overall_W = as.numeric(italy_data$Overall_W)
italy_data$Overall_D = as.numeric(italy_data$Overall_D)
italy_data$Overall_L = as.numeric(italy_data$Overall_L)
italy_data$Overall_A = as.numeric(italy_data$Overall_A)
italy_data$Overall_F = as.numeric(italy_data$Overall_F)
italy_data$Home_W = as.numeric(italy_data$Home_W)
italy_data$Home_D = as.numeric(italy_data$Home_D)
italy_data$Home_L = as.numeric(italy_data$Home_L)
italy_data$Home_F = as.numeric(italy_data$Home_F)
italy_data$Home_A = as.numeric(italy_data$Home_A)
italy_data$Away_W = as.numeric(italy_data$Away_W)
italy_data$Away_D = as.numeric(italy_data$Away_D)
italy_data$Away_L = as.numeric(italy_data$Away_L)
italy_data$Away_F = as.numeric(italy_data$Away_F)
italy_data$Away_A = as.numeric(italy_data$Away_A)
ggplot(italy_data, aes(x = POS, y = PTS/Overall_P, label = TEAM)) +
geom_area(alpha = 0.6, fill = "steelblue2") +
geom_point(aes(color = TEAM, size = PTS)) +
geom_text(aes(label = TEAM), nudge_y = -0.15, angle = 45) +
geom_line()
p = ggplotly()
Sys.setenv("plotly_username"="bendenis")
Sys.setenv("plotly_api_key"="6bSvGX1gICWZ0sAZhkOL")
plotly_POST(p, filename = "footbal_spain")
library(stringr)
library(rvest)
library(ggplot2)
library(plotly)
library(dplyr)
italy_page = read_html("http://www.espnfc.us/french-ligue-1/9/table")
italy_data = html_table(html_nodes(italy_page,"table"), header = T)[[1]]
italy_data = italy_data[,-c(3,10,16,22)]
column_names = str_c(as.character(names(italy_data)),italy_data[1,], sep = "_")
column_names = str_replace(column_names,".[0-9]","")
column_names = str_replace(column_names,"^_","")
colnames(italy_data) = column_names[1:length(column_names)]
italy_data = italy_data[-1,]
italy_data$PTS = as.numeric(italy_data$PTS)
italy_data$GD = as.numeric(italy_data$GD)
italy_data$POS = as.numeric(italy_data$POS)
italy_data$Overall_P = as.numeric(italy_data$Overall_P)
italy_data$Overall_W = as.numeric(italy_data$Overall_W)
italy_data$Overall_D = as.numeric(italy_data$Overall_D)
italy_data$Overall_L = as.numeric(italy_data$Overall_L)
italy_data$Overall_A = as.numeric(italy_data$Overall_A)
italy_data$Overall_F = as.numeric(italy_data$Overall_F)
italy_data$Home_W = as.numeric(italy_data$Home_W)
italy_data$Home_D = as.numeric(italy_data$Home_D)
italy_data$Home_L = as.numeric(italy_data$Home_L)
italy_data$Home_F = as.numeric(italy_data$Home_F)
italy_data$Home_A = as.numeric(italy_data$Home_A)
italy_data$Away_W = as.numeric(italy_data$Away_W)
italy_data$Away_D = as.numeric(italy_data$Away_D)
italy_data$Away_L = as.numeric(italy_data$Away_L)
italy_data$Away_F = as.numeric(italy_data$Away_F)
italy_data$Away_A = as.numeric(italy_data$Away_A)
ggplot(italy_data, aes(x = POS, y = PTS/Overall_P, label = TEAM)) +
geom_area(alpha = 0.6, fill = "steelblue2") +
geom_point(aes(color = TEAM, size = PTS)) +
geom_text(aes(label = TEAM), nudge_y = -0.15, angle = 45) +
geom_line()
p = ggplotly()
Sys.setenv("plotly_username"="bendenis")
Sys.setenv("plotly_api_key"="6bSvGX1gICWZ0sAZhkOL")
plotly_POST(p, filename = "footbal_spain")
library(rvest)
read_html("http://yclist.com/")
ycomb = html_table(read_html("http://yclist.com/"))[[1]]
head(ycomb)
ycomb = html_table(read_html("http://yclist.com/"), header = TRUE)[[1]]
head(ycomb)
View(ycomb)
names(ycomb)
ycomb = ycomb[,-1]
str(ycomb)
ycomb$Class = as.factor(ycomb$Class)
ycomb$Status = as.factor(ycomb$Status)
str(ycomb)
summary(ycomb)
plot(ycomb$Class,ycomb$Status)
heatmap(ycomb$Class,ycomb$Status)
boxplot(ycomb$Class,ycomb$Status)
boxplot(ycomb$Status,ycomb$Class)
plot(ycomb$Class,ycomb$Status)
plot(ycomb$Status,ycomb$Class)
plot(ycomb$Class,ycomb$Status)
library(devtools)
create("/Desktop/testpackage")
create("/DESKTOP/testpackage")
create(".../Descktop/testpackage")
getwd()
create("/Users/bendenisshaffer/Desktop/testpackage")
pnorm(1)
pnorm(-1.29)
?pnorm
qnorm(-1.29)
dnorm(-1.29)
pnorm(0)
pnorm(1.96)
pnorm(-1.96)
pnorm(-1.29)
pnorm(1.96)
pnorm(-1.29)
library(reshape2)
library(ggplot2)
ggplot_missing <- function(x){
x %>%
is.na %>%
melt %>%
ggplot(data = .,
aes(x = X2,
y = X1)) +
geom_raster(aes(fill = value)) +
scale_fill_grey(name = "",
labels = c("Present","Missing")) +
theme_minimal() +
theme(axis.text.x  = element_text(angle=45, vjust=0.5)) +
labs(x = "Variables in Dataset",
y = "Rows / observations")
}
setwd("~/Box_Sync/UM_Winter_2017/STATS_503/Project/503_proj")
library(foreign)
library(dplyr)
library(ggplot2)
library(parallel)
files = dir()[c(1:4,7)]
data = lapply(files, read.arff)
polish_dt = data[[1]]
polish_dt$year = 1
for(i in 2:length(data)) {
df = data[[i]]
df$year = i
polish_dt = rbind(polish_dt,df)
}
ggplot_missing(polish_dt)
missing = apply(polish_dt,2, fucntion(x) sum(is.na(x))
missing = apply(polish_dt,2, fucntion(x) sum(is.na(x)))
missing = apply(polish_dt,2, fucntion(x) is.na(x))
apply(polish_dt,2,function(x) sum(is.na(x)))
order(apply(polish_dt,2,function(x) sum(is.na(x))))
sort((apply(polish_dt,2,function(x) sum(is.na(x)))))
sort(-(apply(polish_dt,2,function(x) sum(is.na(x)))))
-sort(-(apply(polish_dt,2,function(x) sum(is.na(x)))))
missing = data.frame(-sort(-(apply(polish_dt,2,function(x) sum(is.na(x))))))
missing
colnames(missing) = c("Attr", "Num_Missing")
missing = data.frame(-sort(-(apply(polish_dt,2,function(x) sum(is.na(x))))))
colnames(missing) = c("Attr", "Num_Missing")
colnames(missing) = c("Num_Missing")
head(missing)
row.names((missing()))
row.names(missing)
missing = cbind(missing, row.names(missing))
head(colnames(missing) = c("Num_Missing"))
head(missing)
require(ggplot2)
require(ggthemes)
require(ggplot2)
require(ggthemes)
missing = data.frame(-sort(-(apply(polish_dt,2,function(x) sum(is.na(x))))))
missing = cbind(missing, row.names(missing))
colnames(missing) = c("Num_Missing", "Var")
ggplot(missing, aes(y = Num_Missing, x = Var, color = Num_Missing)) + geom_col() + theme_economist()
ggplot(missing, aes(y = Num_Missing, x = Var, fill = Num_Missing)) + geom_col() + theme_economist()
setwd("~/Box_Sync/UM_Winter_2017/STATS_503/Project/503_proj")
library(foreign)
library(dplyr)
library(ggplot2)
library(parallel)
files = dir()[c(1:4,7)]
data = lapply(files, read.arff)
polish_dt = data[[1]]
polish_dt$year = 1
for(i in 2:length(data)) {
df = data[[i]]
df$year = i
polish_dt = rbind(polish_dt,df)
}
setwd("~/Google Drive (shafferbendenis@gmail.com)/Calissification_Prediction_Bankruptcy_Polish_Companies")
dir(path = "data/raw/")
files = dir(path = "data/raw/")
data = lapply(files, read.arff)
files
library(foreign)
library(dplyr)
library(ggplot2)
library(parallel)
data = lapply(files, read.arff)
?read.arff
library(stringr)
files
str_c("data/raw/",files)
files = str_c("data/raw/",dir(path = "data/raw/"))
files
data = lapply(files, read.arff)
polish_dt = data[[1]]
polish_dt$year = 1
for(i in 2:length(data)) {
df = data[[i]]
df$year = i
polish_dt = rbind(polish_dt,df)
}
source("functions/reduce_impute_polish.R")
clean_polish_dt = reduce_impute_polish(polish_dt, margin = 200, rate = 2) #default tolerance arguments can be adjusted.
write.csv(clean_polish_dt, "data/clean/clean_polish_dt.csv")
clean_polish_dt$Attr21 = as.integer(clean_polish_dt$Attr21)
clean_polish_dt$Attr27 = as.integer(clean_polish_dt$Attr27)
clean_polish_dt$Attr28 = as.integer(clean_polish_dt$Attr28)
clean_polish_dt$Attr53 = as.integer(clean_polish_dt$Attr53)
clean_polish_dt$Attr54 = as.integer(clean_polish_dt$Attr54)
clean_polish_dt$Attr64 = as.integer(clean_polish_dt$Attr64)
clean_polish_dt$class = as.integer(clean_polish_dt$class)
clean_polish_dt$year = as.integer(clean_polish_dt$year)
write.csv(clean_polish_dt, "data/clean/clean_polish_dt.csv")
pca = prcomp(log(clean_polish_dt[,-c(58,57,56,47,46,27,26,21,14)]^2 + 1))
var = (pca$sdev^2)/sum(pca$sdev^2)
vd = data.frame(Var = var, PC = 1:49)
ggplot_PCs = ggplot(vd, aes(x = PC, y = Var)) + geom_line() +
geom_col(aes(fill = -Var)) +
labs(title = "Percentage of Variance Explained by PC's", x =" Principal Component ", y = "Variance")+
theme_dark()+ scale_fill_continuous(name = "% of Variance \n explained")+xlim(0,40)
ggplot_PCs
pca = prcomp(log(clean_polish_dt[,-c(58,57,56,47,46,27,26,21,14)]^2 + 1))
pca
class(pca)
var = (pca$sdev^2)/sum(pca$sdev^2)
vd = data.frame(Var = var, PC = 1:49)
ggplot_PCs = ggplot(vd, aes(x = PC, y = Var)) + geom_line() +
geom_col(aes(fill = -Var)) +
labs(title = "Percentage of Variance Explained by PC's", x =" Principal Component ", y = "Variance")+
theme_dark()+ scale_fill_continuous(name = "% of Variance \n explained")+xlim(0,40)
ggplot_PCs
?save
save(ggplot_PCs, "saved_output/plots/pca_plot.png")
?png
png("saved_output/plots/pca_plot.png")
dev.off()
?ggsave
ggsave("saved_output/plots/pac_plot.png", ggplot_PCs, device = "png")
?svae
?save
save(pca, file = "saved_output/objects/pca.RData")
X = as.matrix(log(clean_polish_dt[,-c(58,57,56,47,46,27,26,21,14)]^2 + 1))
M = pca$rotation[,1:5]
PCA_polish_data = as.data.frame((X %*% M))
PCA_polish_data = cbind(PCA_polish_data,clean_polish_dt[,c(58,57,56,47,46,27,26,21,14)])
PCA_polish_data$year = as.factor(PCA_polish_data$year)
PCA_polish_data$class = as.factor(PCA_polish_data$class)
PCA_polish_data
class(PCA_polish_data)
write.csv(PCA_polish_data, "data/clean/pca_polish_dt.csv")
library(GGally)
gg = ggpairs(PCA_polish_data,columns = c(1:7) , mapping = aes(color = class, alpha = 0.35))
gg
?ggsave
ggsave("saved_output/plots/pair_plots", plot = gg, device = "png")
ggsave("saved_output/plots/pair_plots.png", plot = gg, device = "png")
require(dplyr)
require(caTools)
require(randomForest)
data_sp = PCA_polish_data %>% group_by(year) # group them by year / we are using the cleaned file after imputation!!
data_sp$rownumber = 1:nrow(data_sp) # an indicator column for each row to check if the split worked fine
set.seed(123)
sample = sample.split(data_sp, SplitRatio = 2/3) # we pick 2/3 split ratio
train = subset(data_sp, sample == TRUE) %>% as.data.frame() # 2/3 proportion of the training set
test = subset(data_sp, sample == FALSE) %>% as.data.frame() # 1/3 proportion for the test set
train = subset(train , select = -rownumber)
test = subset(test , select = -rownumber)
Xtrain = train[,c(1:6,8:14)]
Ytrain = train$class
Xtest = test[,c(1:6,8:14)]
Ytest = test$class
md = list(1,2,3,4,5,6,7,8,9,10)
for(i in 1:10){
rf = randomForest(x = Xtrain,
y = Ytrain,
ntree = 1000,
mtry = i,
xtest = Xtest,
ytest = Ytest)
md[[i]] = rf
}
md
save(md, "saved_output/objects/rf.RData")
save(md, file = "saved_output/objects/rf.RData")
?write.csv
?write.table
write.csv(train, "data/clean/train.csv")
write.csv(test, "data/clean/test.csv")
par(mfrow = c(1,3))
plot(md[[1]]$err.rate[1:200,3], type = "l", ylim = c(0.65,1), main = "False Positive Rate")
for(i in 2:10){
lines(md[[i]]$err.rate[1:200,3], col = i)
}
plot(md[[1]]$err.rate[1:200,2], type = "l", ylim = c(0,0.04), main = "False Negative Rate")
for(i in 2:10){
lines(md[[i]]$err.rate[1:200,2], col = i)
}
plot(md[[1]]$err.rate[1:200,1], type = "l", ylim = c(0.035,0.07), main = "OOB error")
for(i in 2:10){
lines(md[[i]]$err.rate[1:200,1], col = i)
}
?png
png(filename = "rf_plots.png")
png(filename = "saved_output/plots/rf_plots.png")
dev.off()
?png
png(file = "saved_output/plots/rf_plots.png")
dev.off()
png(filename = "saved_output/plots/rf_plots.png")
dev.off()
png(filename = "saved_output/plots/rf_plots.png")
par(mfrow = c(1,3))
plot(md[[1]]$err.rate[1:200,3], type = "l", ylim = c(0.65,1), main = "False Positive Rate")
for(i in 2:10){
lines(md[[i]]$err.rate[1:200,3], col = i)
}
plot(md[[1]]$err.rate[1:200,2], type = "l", ylim = c(0,0.04), main = "False Negative Rate")
for(i in 2:10){
lines(md[[i]]$err.rate[1:200,2], col = i)
}
plot(md[[1]]$err.rate[1:200,1], type = "l", ylim = c(0.035,0.07), main = "OOB error")
for(i in 2:10){
lines(md[[i]]$err.rate[1:200,1], col = i)
}
dev.off()
png(filename = "saved_output/plots/rf_plots.png", width = 1200)
par(mfrow = c(1,3))
plot(md[[1]]$err.rate[1:200,3], type = "l", ylim = c(0.65,1), main = "False Positive Rate")
for(i in 2:10){
lines(md[[i]]$err.rate[1:200,3], col = i)
}
plot(md[[1]]$err.rate[1:200,2], type = "l", ylim = c(0,0.04), main = "False Negative Rate")
for(i in 2:10){
lines(md[[i]]$err.rate[1:200,2], col = i)
}
plot(md[[1]]$err.rate[1:200,1], type = "l", ylim = c(0.035,0.07), main = "OOB error")
for(i in 2:10){
lines(md[[i]]$err.rate[1:200,1], col = i)
}
dev.off()
PCA_polish_data = read.csv("data/clean/pca_polish_dt.csv")
head(PCA_polish_data)
?read.csv
head(clean_polish_dt)
write.csv(clean_polish_dt, "data/clean/clean_polish_dt.csv", row.names = FALSE)
clean_polish_dt = read.csv("data/clean/clean_polish_dt.csv")
head(clean_polish_dt)
X = as.matrix(log(clean_polish_dt[,-c(58,57,56,47,46,27,26,21,14)]^2 + 1))
M = pca$rotation[,1:5]
PCA_polish_data = as.data.frame((X %*% M))
PCA_polish_data = cbind(PCA_polish_data,clean_polish_dt[,c(58,57,56,47,46,27,26,21,14)])
PCA_polish_data$year = as.factor(PCA_polish_data$year)
PCA_polish_data$class = as.factor(PCA_polish_data$class)
write.csv(PCA_polish_data, "data/clean/pca_polish_dt.csv", row.names = FALSE)
PCA_polish_data = read.csv("data/clean/pca_polish_dt.csv")
head(PCA_polish_data)
data_sp = PCA_polish_data %>% group_by(year) # group them by year / we are using the cleaned file after imputation!!
data_sp$rownumber = 1:nrow(data_sp) # an indicator column for each row to check if the split worked fine
set.seed(123)
sample = sample.split(data_sp, SplitRatio = 2/3) # we pick 2/3 split ratio
train = subset(data_sp, sample == TRUE) %>% as.data.frame() # 2/3 proportion of the training set
test = subset(data_sp, sample == FALSE) %>% as.data.frame() # 1/3 proportion for the test set
# the split worked fine so if we want
# we can delete the extra column
train = subset(train , select = -rownumber)
test = subset(test , select = -rownumber)
write.csv(train, "data/clean/train.csv", row.names = FALSE)
write.csv(test, "data/clean/test.csv", row.names = FALSE)
head(train)
train = read.csv("data/clean/train.csv")
head(train)
head(test)
test = read.csv("data/clean/test.csv")
head(test)
test_error = list(1,2,3,4,5,6,7,8,9,10)
for(i in 1:10){
test_error[[i]] = table(test$class,md[[i]]$test[1]$predicted)
}
train_error = list(1,2,3,4,5,6,7,8,9,10)
for(i in 1:10){
train_error[[i]] = md[[i]]$confusion
}
testing_FPR = sapply(test_error, function(x) 1 -  x[2,2]/(x[2,1]+x[2,2]))
training_FPR = sapply(train_error, function(x) 1 - x[2,2]/(x[2,1]+x[2,2]))
require(randomForest)
require(ggplot2)
require(gridExtra)
df = data.frame(Error = c(testing_FPR,training_FPR),
Set = c(rep("Test",10),rep("Train",10)),
M = rep(1:10,2))
g1 = ggplot(df, aes(x = M, y = Error, color = Set)) +
geom_line(size = 1) +
labs(title = "False Positive Rate on Testing and Training Sets")+
theme_bw()%+replace%theme(legend.position ="bottom",
legend.direction = "vertical",legend.title = element_blank())
### Plot of FNR for Training and Testing Data
testing_FNR = sapply(test_error, function(x) x[1,2]/(x[1,1]+x[1,2]))
training_FNR = sapply(train_error, function(x) x[1,2]/(x[1,1]+x[1,2]))
df = data.frame(Error = c(testing_FNR,training_FNR),
Set = c(rep("Test",10),rep("Train",10)),
M = rep(1:10,2))
g2 = ggplot(df, aes(x = M, y = Error, color = Set)) +
geom_line(size  = 1) +
labs(title = "False Negative Rate on Testing and Training Sets")+
theme_bw()%+replace%theme(legend.position ="bottom",
legend.direction = "vertical",legend.title = element_blank())
grid.arrange(g1,g2, ncol = 2, nrow = 1)
g = grid.arrange(g1,g2, ncol = 2, nrow = 1)
g
ggsave(filename = "rf_FPR_FNR_plots.png", plot = g, device = "png")
ggsave(filename = "saved_output/plots/rf_FPR_FNR_plots.png", plot = g, device = "png")
cost = c(1,2,4,6,8,10,12,14,16)  #define list of tuning parameters
fit_svm = function(cost){
gaussian_ksvm <- ksvm(class ~ ., data = train,
kernel = "rbfdot",
kpar = list(sigma=0.05),
C = cost,
cross = 4)
return(gaussian_ksvm)
}
gaussian_svm = mclapply(cost, fit_svm)
gaussian_svm
require(kernlab)
require(parallel)
require(ggthemes)
fit_svm = function(cost){
gaussian_ksvm <- ksvm(class ~ ., data = train,
kernel = "rbfdot",
kpar = list(sigma=0.05),
C = cost,
cross = 4)
return(gaussian_ksvm)
}
gaussian_svm = mclapply(cost, fit_svm)
gaussian_svm
save(gaussian_svm, file = "saved_output/objects/gaussian_svm.RData")
gaussian_svm_tb_train = function(model){
pred_pca_ksvm = predict(model, train[,-7])
tb = table(pred_pca_ksvm, train[,7])
return(tb)
}
gaussian_svm_tb_test = function(model){
pred_pca_ksvm = predict(model, test[,-7])
tb = table(pred_pca_ksvm, test[,7])
return(tb)
}
train_confusion_svm = mclapply(gaussian_svm, gaussian_svm_tb_train)
test_confusion_svm = mclapply(gaussian_svm, gaussian_svm_tb_test)
train_confusion_svm
gaussian_testing_FPR_svm = sapply(test_confusion_svm, function(x) 1 -  x[2,2]/(x[2,1]+x[2,2]))
gaussian_training_FPR_svm = sapply(train_confusion_svm, function(x) 1 - x[2,2]/(x[2,1]+x[2,2]))
df_svm_FPR = data.frame(Error = c(gaussian_testing_FPR_svm,gaussian_training_FPR_svm),
Set = c(rep("Test",length(cost)),rep("Train",length(cost))),
Cost = rep(cost,2))
g1 = ggplot(df_svm_FPR, aes(x = Cost, y = Error, color = Set)) +
geom_line(size = 1) +
labs(title = "False Positive Rate/\nTesting&Training Sets SVM")+
theme_economist()%+replace%theme(legend.position ="bottom",
legend.direction = "vertical",
legend.title = element_blank())+scale_color_colorblind()
df_svm_FNR = data.frame(Error = c(gaussian_testing_FNR_svm,gaussian_training_FNR_svm),
Set = c(rep("Test",length(cost)),rep("Train",length(cost))),
Cost = rep(cost,2))
g2 = ggplot(df_svm_FNR, aes(x = Cost, y = Error, color = Set)) +
geom_line(size = 1) +
labs(title = "False Negative Rate/\nTesting&Training Sets SVM")+
theme_economist()%+replace%theme(legend.position ="bottom",
legend.direction = "vertical",
legend.title = element_blank())+scale_color_colorblind()
gaussian_testing_FNR_svm = sapply(test_confusion_svm, function(x) x[1,2]/(x[1,1]+x[1,2]))
gaussian_training_FNR_svm = sapply(train_confusion_svm, function(x) x[1,2]/(x[1,1]+x[1,2]))
df_svm_FNR = data.frame(Error = c(gaussian_testing_FNR_svm,gaussian_training_FNR_svm),
Set = c(rep("Test",length(cost)),rep("Train",length(cost))),
Cost = rep(cost,2))
g2 = ggplot(df_svm_FNR, aes(x = Cost, y = Error, color = Set)) +
geom_line(size = 1) +
labs(title = "False Negative Rate/\nTesting&Training Sets SVM")+
theme_economist()%+replace%theme(legend.position ="bottom",
legend.direction = "vertical",
legend.title = element_blank())+scale_color_colorblind()
gaussian_cv_error = sapply(gaussian_svm, function(x) x@cross)
gaussian_mean_error_train = sapply(gaussian_svm, function(x) x@error)
gaussian_mean_error_test = sapply(test_confusion_svm, function(x) (x[2,1]+x[1,2])/sum(x))
df_svm_cv_mean = data.frame(Error = c(gaussian_cv_error, gaussian_mean_error_train, gaussian_mean_error_test),
Type = c(rep("CV",length(cost)), rep("Train",length(cost)),rep("Test",length(cost))),
Cost = rep(cost,3))
g3 = ggplot(df_svm_cv_mean, aes(x = Cost, y = Error, color = Type)) +
geom_line(size = 1) +
labs(title = "SVM Mean and CV error")+
theme_economist()%+replace%theme(legend.position ="bottom",
legend.direction = "vertical",
legend.title = element_blank())+scale_color_colorblind()
require(gridExtra)
grid.arrange(g1,g2,g3, ncol = 3, nrow = 1)
g1
grid.arrange(g1,g2,g3, ncol = 3, nrow = 1)
train_confusion_svm = mclapply(gaussian_svm, gaussian_svm_tb_train)
test_confusion_svm = mclapply(gaussian_svm, gaussian_svm_tb_test)
df_svm_FPR = data.frame(Error = c(gaussian_testing_FPR_svm,gaussian_training_FPR_svm),
Set = c(rep("Test",length(cost)),rep("Train",length(cost))),
Cost = rep(cost,2))
g1 = ggplot(df_svm_FPR, aes(x = Cost, y = Error, color = Set)) +
geom_line(size = 1) +
labs(title = "False Positive Rate/\nTesting&Training Sets SVM")+
theme_economist()%+replace%theme(legend.position ="bottom",
legend.direction = "vertical",
legend.title = element_blank())+scale_color_colorblind()
g1
grid.arrange(g1,g2,g3, ncol = 3, nrow = 1)
